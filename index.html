<!doctype html>

<html lang="en">

<head>
    
    <meta charset="UTF-8">
    <meta name="description" content="WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics">
    <link rel="stylesheet" href="https://fonts.sandbox.google.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>UIClip: A Data-driven Model for Assessing User Interface Design</title>
    <link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
    <link rel="icon" type="image/png" href="static/favicon.png">
    <!-- <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png"> -->
    <link rel="manifest" href="site.webmanifest">

    <meta name="theme-color" content="#f5ece5">
    <link rel="mask-icon" href="safari-pinned-tab.svg" color="#276FBF">
    <meta name="msapplication-TileColor" content="#276FBF">
    <link rel="stylesheet" href="fonts.css">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,900" rel="stylesheet">
    
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.10/clipboard.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.0.1/dist/js/splide.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@splidejs/splide-extension-intersection@0.2.0/dist/js/splide-extension-intersection.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@splidejs/splide@4.0.1/dist/css/splide.min.css">
    <!-- <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script> -->
    <style>
        .material-symbols-rounded {
            font-variation-settings: 'FILL' 1,
            'wght' 400,
            'GRAD' 0,
            'opsz' 48
        }


        @font-face {
            font-family: 'Code';
            /* src: url('/fonts/IBMPlexMono-Light.ttf'); */
            src: url('fonts/SourceSansPro-Light.ttf');
        }

        .tooltip-inner {
            /* font-family: 'GT Ultra', sans-serif !important; */
            font-family: 'Source Sans Pro', sans-serif !important;
        }


        h3 span i, h5 span i {
            order: -1;
        }

        body {
            position: relative;
        }

        html, body {
            /* font-family: 'GT Ultra', sans-serif !important; */
            font-family: 'Source Sans Pro', sans-serif !important;
            font-weight: 200;
            font-size: 20px;
            overflow-x: hidden;
            box-sizing: border-box;
            color: #1f1e1d;
            background-color: #f5ece5;

            /*     background-color: #1f1e1d;*/
            /*color: #d7c0af;*/
            /*font-family: sans-serif;*/
        }

        *, *:before, *:after {
            box-sizing: inherit;
        }

        header {
            text-align: center;
        }

        a {
            color: #6522c2ec !important;
            text-decoration: none;
            font-weight: 300;
        }

        a:hover {
            text-decoration: underline;
            color: #184477 !important;
            /*font-weight: 700;*/
        }

        /* Heart beat animation */


        .heart:hover div * {
            color: #B33951 !important;
            cursor: initial !important;
        }

        .authors {
            display: flex;
            justify-content: center;
            max-width: 1050px;
            flex-wrap: wrap;
            margin: 0 auto;
            font-size: 1.1em;
            
        }

        .autoplaytoggle {
            margin: -1rem;
            text-align: center;
            display: flex;
            justify-content: center;
        }

        .autoplaytoggle button {
            align-items: center;
        }

        .autoplaytoggle span.material-symbols-rounded {

            font-size: 1.25rem !important;
        }

        .insts {
            display: flex;
            justify-content: center;
        }

        header h1 {
            margin-bottom: 0;
            font-weight: 700;
        }

        .carousel-item img {
            max-width: 100%;
        }

        .insts {
            font-size: 17px;
        }

        .linkscontainer {
            max-width: 700px;
            margin: 0 auto;
        }

        .links {
            /*font-size: 5rem;*/
            /*margin: 0 -20px;*/
            display: flex;
            gap: 20px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .links a span.material-symbols-rounded {
            max-width: 25px;
        }

        span.material-symbols-rounded {
            max-width: 25px;
        }

        .links a {
            display: inline-flex;
            /*flex-direction: column;*/
            align-items: center;
            text-decoration: none;
            border-radius: 5px;
            padding: 5px 7px;
            color: #f6f3f1 !important;
            /* font-family: 'GT Ultra', sans-serif !important; */
            font-family: 'Source Sans Pro', sans-serif !important;
            font-weight: 200;
            /*margin: 0 10px;*/
            transition: transform .2s;
            background-color: rgba(var(--btn-bgc), 1);
        }


        .links a:nth-child(1) {
            /* --btn-bgc: 237, 100, 90; */
            --btn-bgc: 237,167,201;
        }

        .links a:hover {
            transform: scale(1.2);
            color: #f6f3f1 !important;
        }

        .links a:active {
            transform: scale(1.3);
        }

        .links a:nth-child(2) {
            /* --btn-bgc: 47, 138, 196; */
            --btn-bgc: 123,146,220;
            
        }

        .links a:nth-child(3) {
            /* --btn-bgc: 229, 134, 6; */
            /* --btn-bgc: 245,206,90; */
            --btn-bgc: 235,194,12;
        }

        .links a:nth-child(4) {
            /* --btn-bgc: 133, 180, 51; */
            --btn-bgc: 227,90,67;
        }

        .links a:nth-child(5) {
            /* --btn-bgc: 204, 97, 176; */
            --btn-bgc: 79,49,45;
        }

        .links a span.material-symbols-rounded {
            margin-right: .25rem;
        }

        .links a:not(:last-child) {
            /*margin-right: 20px;*/
        }


        .links .material-symbols-rounded {
            font-size: 1.25rem;
        }


        .links i {
            font-size: 28px;
        }

        .fig {
            width: 100%;
            display: block;
            padding: 0 10px;
            margin: 0 auto;
        }

        img.arch {
            max-width: 500px;
        }

        img.blobs {
            max-width: 350px;
        }

        .teaser {
            text-align: center;
            margin-bottom: 1rem;
        }

        .teaser + section {
            margin-top: 1rem;
        }

        .teaser video {
            max-width: 600px;
            width: 100%;
        }
        
        .teaser img {
            max-width: 750px;
            width: 100%;
        }

        img.teaser {
            max-width: 90%;
        }

        .example {
            max-width: 1000px;
            max-height: 1000px;
        }

        .example3 {
            max-width: 500px;
            max-height: 1000px;
            margin-left: 25%;
        }

        .abstract-imgs .col {
            display: flex;
            align-items: center;
        }

        .videowrapper {
            float: none;
            clear: both;
            width: 100%;
            position: relative;
            padding-bottom: 56.25%;
            padding-top: 25px;
            height: 0;
        }

        .wrapwrap {
            max-width: 800px;
            margin: 0 auto;
        }

        .videowrapper iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        .abstract-capt {
            font-size: 0.8rem;
            display: block !important;
            text-align: center;
        }

        .latex {
            display: inline;
            font-family: 'Math', monospace;
            font-style: italic;
        }

        p {
            margin: 0 !important;
        }

        .bs-tooltip-end {
            margin-left: 3px !important;
        }

        section {
            margin: 2rem 0;
            text-align: justify;
            word-break: keep-all;
        }

        section h5 {
            margin: 1.5rem 0 0.75rem 0;
        }

        .iconbutton {
            padding: 0.1rem 0.3rem;
            display: flex;
            border: none !important;
            background-color: #4B495B !important;
            color: #f5ece5 !important;
            /* font-family: 'GT Ultra', sans-serif !important; */
            font-family: 'Source Sans Pro', sans-serif !important;
            font-weight: 600;
            text-decoration: none !important;
        }

        .iconbutton span.material-symbols-rounded {
            font-size: 1.5rem;
            /* font-weight: 700; */
        }

        .playpause span.material-symbols-rounded {
            font-variation-settings: 'wght' 700;


        }

        .iconbutton span.material-symbols-rounded:hover {
            color: #faf6f2 !important;
        }

        .iconbutton:hover, .iconbutton:focus {
            background-color: #2E2E38 !important;
            border-color: none !important;
            color: #faf6f2 !important;
        }

        .iconbutton:focus {

        }

        .iconbutton:active {
            background-color: #09090B !important;

        }

        [data-clipboard-target] {
            cursor: pointer;
        }

        [data-clipboard-target]:hover {
            color: #276FBF !important;
        }

        /* .emptyrooms {
             max-width: 80%;
         }*/

        .emptyrooms {
            display: flex;
            /*justify-content: center;*/
            align-items: flex-start;
            background-color: #f5ece5;
        }

        .playpause {
            flex-shrink: 0;
        }

        .emptyrooms img:first-child {
            width: 16.196944%;
            margin-right: 0.6%;
        }

        .emptyrooms img:last-child {
            width: 82.8862479%;
        }


        section h3 {
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
        }

        section h5, section h3 {
            justify-content: space-between;

            display: flex;
            align-items: center;
        }

        h3, h5 {
            scroll-margin-top: 25px;
            /*display: inline-block;*/
        }

        h3[data-exclude-link], h5[data-exclude-link] {
            cursor: initial;
        }

        h3 span, h5 span {
            display: inline-flex;
            align-items: center;
            /* cursor: pointer; */
        }

        /* h3 span:hover, h5 span:hover {

            color: #276FBF !important;
        } */

        /*
                h3[data-exclude-link]:hover, h5[data-exclude-link]:hover {
                    color: initial !important;
                }*/

        .carousel {
            margin: 1rem 0;
        }

        .ltx {
            vertical-align: baseline;
        }

        .cit {
            background-color: rgba(26, 25, 31, 0.05);
            padding: 10px;
            border-radius: 5px;
            font-size: 18px;
            display: inline-block;
            margin: 0 auto;
            overflow-y: hidden;
            overflow-x: auto;
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
            font-family: 'Source Sans Pro', monospace;
        }

        .cit_cont {
            display: flex;
        }

        .video-container {
            position: relative;
        }

        /* .video-container .video-border {
             position: absolute;
             width: 100%;
             height: 100%;
             top: 0;
             left: 0;
             box-shadow: inset 0px 0px 0px 6px #f5ece5;
         }*/

        .video-container video {
            width: 100%;
            display: block;
            clip-path: inset(5px 5px);
        }

        .video-container img {
            width: 100%;
        }

        .splide > * {
            font-weight: 500;
            position: initial;
        }

        .splide__arrow {
            position: initial;
            background: none;
            /*opacity: 1;*/
            -webkit-transform: none;
            -moz-transform: none;
            -ms-transform: none;
            -o-transform: none;
            transform: none;
            font-size: 1.25rem;
            justify-content: end;
            width: 1.5em;
        }

        .splide__arrow--prev {
            justify-content: left;
        }

        .splide__slide {
            height: 0;
        }

        .splide__slide.is-visible {
            height: auto;
        }

        .move-cont {
            display: flex;
        }

        .move-cont > video {
            max-width: 100%;
        }

        .splide__pagination__page.is-active {
            background: #000;
        }

        .splide__pagination__page {
            -webkit-transition: all 0.3s;
            -moz-transition: all 0.3s;
            -ms-transition: all 0.3s;
            -o-transition: all 0.3s;
            transition: all 0.3s;
        }

        .splide__pagination {
            margin-top: 0.25rem;
        }

        .splide__pagination__page:hover {
            background: #aaa;
            transform: scale(1.2);
        }

        .splide__track_and_arrows {
            display: flex;
        }

        .splide__arrows {
            display: flex;
            align-items: center;
        }

        .styletransfer {
            display: grid;
            grid-row-gap: .5rem;
            grid-template-columns: 1fr 20px 1fr 1fr 1fr 20px 1fr 1fr 1fr;
        }

        .inversion {
            display: grid;
            /*grid-row-gap: .5rem;*/
            /*grid-template-columns: 1fr 20px 1fr 1fr 1fr 20px 1fr 1fr 1fr;*/
            grid-template-columns: 1fr 1fr 1fr 1fr 1fr;
        }

        .styletransfer img {
            max-width: 100%;
            clip-path: inset(2px 2px);
        }

        .inversion span {
            text-align: center;
        }

        .inversion img {
            max-width: 100%;
            clip-path: inset(2px 2px);
        }


        #inversion ~ .splide img {
            max-width: 100%;
            padding: 0.3rem;
        }

        .styletransfer span {
            text-align: center;
        }

        .styletransfer span:nth-child(2) {
            grid-column-start: 3;
            grid-column-end: 6;
        }

        .styletransfer span:nth-child(3) {
            grid-column-start: 7;
            grid-column-end: 10;
        }


        @media (min-width: 992px) {
            .container {
                max-width: 1050px;
            }
        }

        .inversion_subheader {
            font-weight: bold;
            text-align: center;
            margin-top: 0.5rem;
        }

        .inversion_subheader:not(:first-of-type) {
            margin-top: 0.2rem;
        }

        .inversion_subheader + .splide {
            margin: 0.2rem 0 !important;
        }

        /*
                .move-cont .video-container:nth-child(8), .move-cont .video-container:nth-child(7) {
                    display: none;
                }*/

        @media (max-width: 991px) {
            /*
                        .move-cont .video-container:nth-child(5), .move-cont .video-container:nth-child(6) {
                            display: none;
                        }*/
            .move-cont > video {
                max-width: 150%;
                clip-path: inset(0 33.333333% 0 0);
            }

            header h3 {
                font-size: 1.5rem;
            }

            .cit {
                /*font-size: 12px !important;*/
            }

            .emptyrooms img:last-child {
                width: 99.6% !important;
            }

            .emptyrooms img:first-child {
                width: 19.46% !important;
                margin-right: 0.7522% !important;
            }

            .styletransfer {
                display: grid;
                grid-template-columns: 1fr 15px 1fr 1fr 15px 1fr 1fr !important;
            }

            .styletransfer img:nth-child(9n+3), .styletransfer img:nth-child(9n-1) {
                display: none;
            }

            .styletransfer span:nth-child(2) {
                grid-column-start: 3;
                grid-column-end: 5;
            }

            .styletransfer span:nth-child(3) {
                grid-column-start: 6;
                grid-column-end: 8;
            }
        }

        .author {
            padding: 0 0.6rem;
        }

        @media (max-width: 767px) {
            html, body {

                /*font-size: 16px;*/
            }

            .author {
                font-size: 18px;
            }

            .insts {
                font-size: 16px;
            }

            /*.move-cont .video-container:nth-child(4) {
                display: none;
            }*/
            .move-cont > video {
                max-width: 200%;
                clip-path: inset(0 50% 0 0);
            }

            .inversion *:nth-child(5n+2) {
                display: none;
            }

            .inversion {
                grid-template-columns: 1fr 1fr 1fr 1fr;
            }

            .emptyrooms img:last-child {
                width: 124.477307% !important;
            }

            .emptyrooms img:first-child {
                width: 24.3243243% !important;
                margin-right: 0.9% !important;
            }

            .styletransfer {
                display: grid;
                grid-template-columns: 1fr 10px 1fr 10px 1fr !important;
            }

            .styletransfer img:nth-child(9n+2), .styletransfer img:nth-child(9n-2) {
                display: none;
            }

            .styletransfer span:nth-child(2) {
                grid-column-start: 3;
                grid-column-end: 4;
            }

            .styletransfer span:nth-child(3) {
                grid-column-start: 5;
                grid-column-end: 6;
            }
        }

        @media (max-width: 540px) {
            .links a span.material-symbols-rounded {
                max-width: 20px;
            }

            .links {
                gap: 12px;
            }
        }

        @media (max-width: 510px) {
            /*
                        .move-cont .video-container:nth-child(3) {
                            display: none;
                        }*/
            .move-cont > video {
                max-width: 300%;
                clip-path: inset(0 66.6666666% 0 0);
            }


            .inversion {
                grid-template-columns: 1fr 1fr;
            }

            .inversion span:nth-child(n+4) {
                grid-row: 3;
            }

            .links .material-symbols-rounded {
                /*display: none;*/
                font-size: 1rem;
            }

            .links a span.material-symbols-rounded {
                max-width: 18px;
            }

        }

        @media (max-width: 399px) {

        }

        @media (max-width: 380px) {
            /*.links .material-symbols-rounded {*/
            /*    display: none;*/
            /*    padding: 5px 10px;*/
            /*    !*font-size: 1rem;*!*/
            /*}*/
        }

        @media (max-width: 575px) {

            img.blobs {
                max-width: 300px;
            }

            .emptyrooms img:last-child {
                width: 165.941536% !important;
            }

            .emptyrooms img:first-child {
                width: 32.4269205% !important;
                margin-right: 1.15% !important;
            }
        }

        @media (min-width: 768px) {
            .abstract-imgs .col-md-7 {
                border-right: 1px solid #1f1e1d;
            }

            img.arch, img.blobs {
                max-width: 600px;
            }

        }
        .py-3{
            padding-bottom: 0rem!important;
        }
        .mt-4 {
            margin-top: 0rem!important;
        }



    </style>
</head>
<body class="h-100 d-flex flex-column">
<main class="container flex-grow-1" style>
    <header class="py-3">
        
        
        <h2 class="mt-1 mt-sm-2 mt-md-3" style="font-weight: 200"><span style="font-weight: 900; margin-right: 3px;">UIClip:  </span>A Data-driven Model for Assessing User Interface Design</h2>
        <div class="authors mt-3">
            <div class="author"><a href="https://jasonwunix.com/" style="font-weight: 200">Jason Wu</a><sup>1</sup></div>
            <div class="author"><a href="https://www.yihaopeng.tw/" style="font-weight: 200">Yi-Hao Peng</a><sup>1</sup></div>
            <div class="author"><a href="https://www.linkedin.com/in/amanda--li" style="font-weight: 200">Amanda Xin Yue Li</a><sup>1</sup></div>
            <div class="author"><a href="https://amaswea.github.io/" style="font-weight: 200">Amanda Swearngin</a><sup>2</sup></div>
            <div class="author"><a href="https://www.cs.cmu.edu/~jbigham/" style="font-weight: 200">Jeffrey Bigham</a><sup>1</sup></div>
            <div class="author"><a href="http://www.jeffreynichols.com/" style="font-weight: 200">Jeffrey Nichols</a><sup>2</sup></div>
        </div>
        <div class="insts mt-1">
            <div class="inst pe-3"><sup>1</sup>Carnegie Mellon University</div>
            <div class="inst pe-3"><sup>2</sup>Apple</div>
        </div>
        <div class="insts mt-1">
            <b>ACM UIST 2024</b>
        </div>
        <section class="teaser mt-2">
            <!-- <video src="static/webui_intro.mp4" alt="A short slide animation showing the overivew of WebUI." data-no-pause autoplay playsinline muted loop></video> -->
            <!-- <img src="static/diagram_element_detection.png" alt="A short slide animation showing the overivew of WebUI."> -->
            <img src="static/jitters.png" alt="">
        </section>
        <div class="linkscontainer">
            <div class="links mt-4">
                <a href="https://huggingface.co/collections/biglab/uiclip-uist-2024-6717dff62c1d222efd222429" target="_blank" style="font-weight: 600"><span class="material-symbols-rounded">science</span><span>Dataset</span></a>
                <a href="https://huggingface.co/collections/biglab/uiclip-uist-2024-6717dff62c1d222efd222429" target="_blank" style="font-weight: 600"><span class="material-symbols-rounded">sports_esports</span><span>Models</span></a>
                <a href="" style="font-weight: 600"><span class="material-symbols-rounded">code</span><span>Repo</span></a>
                <a href="https://arxiv.org/abs/2404.12500" target="_blank" style="font-weight: 600"><span class="material-symbols-rounded">description</span><span>Paper</span></a>
                <a href="" style="font-weight: 600"><span class="material-symbols-rounded">format_quote</span><span>Video</span></a>
            </div>
        </div>
    </header>
    <!-- <section class="teaser mt-2">
        <video src="static/webui_intro.mp4" alt="A short slide animation showing the overivew of WebUI." data-no-pause autoplay playsinline muted loop></video>
    </section> -->
    
    <!-- <section>
        <h3 data-exclude-link><span>Video</span>
            <div>
                <a href="static/blobgan_slides.pptx" target="_blank" class="btn px-2 py-1 iconbutton btn-dark"><span class="me-1 material-symbols-rounded">file_download</span> Slides</a>
            </div>
        </h3>
        <div class="wrapwrap">
            <div class="videowrapper">
                <iframe width="560" height="315" src="" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </div>
    </section> -->
    
    <section class="abstract">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> palette </span>Abstract</span></h3>
        <p>
            User interface (UI) design is a difficult yet important task for ensuring the usability, accessibility, and aesthetic qualities of applications. 
            In our paper, we develop a machine-learned model, UIClip, for assessing the design quality and visual relevance of a UI given its screenshot and natural language description. 
            To train UIClip, we used a combination of automated crawling, synthetic augmentation, and human ratings to construct a large-scale dataset of UIs, collated by description and ranked by design quality. Through training on the dataset, UIClip implicitly learns properties of good and bad designs by 
            (i) assigning a numerical score that represents a UI design’s relevance and quality and (ii) providing design suggestions. 
            In an evaluation that compared the outputs of UIClip and other baselines to UIs rated by 12 human designers, we found that UIClip achieved the highest agreement with ground-truth rankings. 
            Finally, we present three example applications that demonstrate how UIClip can facilitate downstream applications that rely on instantaneous assessment of UI design quality: 
            (i) UI code generation, 
            (ii) UI design tips generation, and 
            (iii) quality-aware UI example search.
        </p>

    </section>

<iframe
	src="https://biglab-uiclip-comparisondemo.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

    <section class="dataset">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> dataset </span>Dataset Generation</span></h3>
        <p>We collected over 2.3 million UI screenshots, each paired with natural language text that includes a caption, design quality, and design defects. Since it is prohibitively costly and time-consuming to collect enough human-annotated data to train deep learning models, the majority of our data (over 99.9%) is synthetically generated, and a smaller portion is human-rated by professional designers. We refer to our synthetically-generated dataset as <i>JitterWeb</i> and our human-rated dataset as <i>BetterApp</i>.</p>

            <ul>
                <li><i>JitterWeb</i> - This dataset was created by automatically crawling nearly 300,000 web pages from publicly available sources and applying a set of <i>jitter functions</i> that intentionally introduce design defects. These functions are based on key design principles, altering web elements such as color, font size, layout, and contrast (see hero figure above for more details). Each web page is captured in its original form and then degraded multiple times using different jitter functions to simulate poor design. Captions for each screenshot are generated using pre-trained models, and design defects are automatically recorded based on the applied jitter functions. This dataset enables models to learn about design quality by comparing the original versus jittered versions.</li>
                
                <li><i>BetterApp</i> - This dataset focuses on real-world app UIs and mockups, where design professionals manually rated and compared pairs of screenshots based on their visual design quality (with a totoal of 1200 ratings collected). In a custom web application, designers provided relative rankings and selected specific design principles (e.g., contrast, alignment, proximity) that influenced their decisions. They also improved or generated captions for these UIs, refining the descriptions generated by automated models. By clustering similar UIs together, this dataset offers high-quality, human-generated ratings of UI design, which are critical for validating the model's understanding of good and bad design.</li>
            </ul>

              
            
        </p>

    </section>


    <section class="dataset">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> smart_toy </span>UIClip: Training and Inference</span></h3>
        <p>
            We used the <i>JitterWeb</i> and <i>BetterApp</i> datasets to train a computational model, UIClip, that assesses UI designs from screenshots. 
            While our datasets could be applied to train various models, such as large vision-language models (LVLMs), we adopted the CLIP architecture due to its efficiency and ability to produce numerical scores, aligning with our goal of design assessment. UIClip takes two inputs: an image (e.g., a screenshot of a UI) and a corresponding textual description. The model outputs a single numerical value representing a combined assessment of the UI's design relevance and quality.
        </p>
        <br aria-hidden="true"/>
        <p>
            During training, UIClip was initialized from the pre-trained CLIP B/32 model and finetuned in four stages to learn domain-specific UI features. In the first stage, we used the <i>JitterWeb</i> dataset, training UIClip using the standard CLIP objective, which aligns paired images and text in a shared embedding space. This allowed the model to learn how UI screenshots relate to their descriptions. 
            In the second stage, we introduced a pairwise contrastive learning objective to distinguish good designs from bad ones by comparing jittered and non-jittered UIs. 
            This process was repeated for the <i>BetterApp</i> dataset, incorporating human-rated comparisons and further refining UIClip’s design assessment capabilities.
        </p>

        <br aria-hidden="true"/>
        <p>
            For inference, UIClip applies a sliding window strategy to handle varying UI dimensions, where the input image is resized and split into 224x224 pixel windows. 
            The model encodes each window separately and averages their embeddings, ensuring that the full UI is considered. 
            The final score is computed as the dot product between the image embedding and the text embedding, allowing the model to assess the quality of the UI based on its visual appearance and the provided description. 
            Additionally, UIClip can suggest design improvements by identifying specific design flaws (e.g., poor contrast or bad alignment) from the <i>JitterWeb</i> dataset.
        </p>
    </section>

    <section class="results">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> smart_toy </span>Experiment Results on UI Design Assessment</span></h3>
        <p>
            We conducted a comprehensive evaluation of UIClip across three key aspects of design assessment: <i>UI design quality assessment</i>, <i>design suggestion generation</i>, and <i>design relevance</i>. UIClip’s performance was compared against state-of-the-art models, including large vision-language models (LVLMs) and various CLIP-based baselines. Our results highlight the model’s effectiveness in these tasks, outperforming much larger models in several cases.
        </p>
        <br aria-hidden="true"/>
        <p>
            (i) <strong>Design Quality</strong>: For the task of design quality assessment, we evaluated how accurately the models identified the "preferred" UI from a pair of examples. UIClip, particularly the variant trained with jittered web pairs from the <i>JitterWeb</i> dataset, achieved the highest accuracy (75.12%) across both synthetic and human-rated datasets. 
            This performance was notably better than the base CLIP model, which struggled with jittered websites and exhibited erroneous associations between certain design defects and better design quality.
            Interestingly, human-rated examples from <i>BetterApp</i> proved more challenging, as UIClip's accuracy slightly dropped to 73.88%, likely due to the complexity and subjectivity of human annotations. 
            Larger LVLMs like GPT-4V and Gemini-1.0-Pro underperformed on design quality assessment, with GPT-4V showing accuracy as low as 51.58%, partially due to refusals to respond to certain examples. 
            These findings reinforce the effectiveness of UIClip’s training approach, which combines paired examples and contrastive learning to assess relative UI design quality.
        </p>
        <br aria-hidden="true"/>
    
        <p>
            (ii) <strong>Design Suggestions</strong>: To evaluate design suggestions, we compared model-generated outputs to CRAP (Contrast, Repetition, Alignment, Proximity) principles selected by human designers in the <i>BetterApp</i> dataset. 
            Despite being a challenging task, UIClip consistently outperformed baseline models, achieving the best F1 scores in both the raw and choice-adjusted metrics. 
            UIClip’s training on jittered websites enabled it to effectively detect design defects and generate suggestions, while LVLMs often over-generated suggestions, leading to inflated recall scores.
            When adjusting for wrong design choices (choice-adjusted F1), UIClip variants maintained high performance, with the full UIClip variant achieving the best results after adjusting for incorrect reasoning. 
            CLIP models trained on alternative datasets, such as Screen2Words, did not perform well due to the absence of training data containing relevant design defects.
        </p>
        <br aria-hidden="true"/>

        <p>
            (iii) <strong>Design Relevance</strong>: For design relevance, we assessed each model’s ability to retrieve the correct UI based on textual descriptions, using mean reciprocal rank (MRR) as the evaluation metric. 
            UIClip, pretrained on <i>JitterWeb</i> with the default CLIP objective, achieved the highest MRR scores (0.3851 on <i>BetterApp</i> and 0.4085 on <i>JitterWeb</i>). 
            This result indicates superior performance in retrieving relevant examples based on the design quality described in the captions.
            Interestingly, UIClip models trained with the pairwise contrastive objective, while excelling in design comparison tasks, performed worse in relevance retrieval. 
            This result suggests that task-specific training objectives play a crucial role in determining model success in different areas of design assessment. 
            Despite this, UIClip's overall performance demonstrates the utility of using tailored datasets like <i>JitterWeb</i> and <i>BetterApp</i> for improving design understanding and relevance across multiple applications.
        </p>
    </section>
    
    
    
    <section class="app1">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> shelf_position </span>Example Use Case 1: Improving UI Code Generation</span></h3>
        
        <section class="example teaser mt-2">
            <img src="static/example-app-codegen.png" alt="A short slide animation showing the overivew of WebUI."></img>
        </section>
        
        <p>
            We developed a web application that allows users to generate rendered UI screenshots from a natural language description of a UI design. Users can input their descriptions, which are then formulated into prompts and fed into external large language models (LLMs) like OpenAI GPT-3.5 or Mixtral. These LLMs generate corresponding web code (HTML/CSS), which is rendered as UI screenshots. The key step in this process is the use of UIClip to rank these rendered screenshots based on their design quality.
            In our interface, users receive multiple generated UI outputs—typically, we sample <i>n = 5</i> different outputs—and each is rendered into a screenshot by programmatically controlling a browser. If any external resources (e.g., images) are required, placeholders are inserted to complete the rendering process. These screenshots are then fed into UIClip, which scores them against the user's input description. The outputs are ranked based on UIClip’s scores, and the results are displayed to the user in descending order of design quality.
            This example demonstrates how UIClip can enhance the output of generative models by ranking generated designs, similar to best-of-n sampling techniques. While this method is simple and does not require access to the model's internal weights, it can be computationally intensive during inference, as it requires multiple candidate solutions to be generated and evaluated. 
            For more advanced integration, UIClip could be used as a filtering mechanism during the training of generative models or as a reward model in reinforcement learning fine-tuning approaches. These additional uses could reduce computational costs and improve the quality of the final outputs, but we leave such optimizations for future work.
        </p>
    </section>

    <section class="app2">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> hdr_strong </span>Example Use Case 2: UI Design Tips</span></h3>
        
        <section class="example teaser mt-2">
            <img src="static/example-app-design-recommend.png" alt="A short slide animation showing the overivew of WebUI."></img>
        </section>
        
        <p>
            We developed a tool that enables users to upload screenshots of UI designs to generate helpful design tips, utilizing our model's design suggestion generation capabilities. 
            Based on the user input (e.g., the screenshot of an app UI), the system generates actionable design tips to improve the overall UI quality. 
            For instance, our system may suggest changes such as improving the readability of text or adjusting color choices to enhance contrast.
            While this tool provides useful feedback, it currently offers general suggestions about the entire UI, without pinpointing the exact areas that triggered specific recommendations. 
            This limitation arises from our current approach, which pairs a complete screenshot with a set of design suggestions, without attaching spatial information to particular UI elements. 
            Future improvements could address this by associating design tips with specific regions of the UI, for example by sliding a smaller window across the screenshot and linking the generated suggestions to particular areas. 
            Additionally, collecting data that includes both design feedback and the location of design flaws would enable the model to provide more targeted suggestions. 
            These enhancements would make the system even more precise and useful for users, and we leave these improvements to future work.
        </p>

        <br aria-hidden="true"/>

        <!-- <iframe
        src="https://biglab-webui-screenclassification.hf.space"
        frameborder="0"
        width="1000"
        height="550"
    ></iframe> -->

    </section>

    <section class="app3">
        <h3 data-exclude-link><span><span class="me-2 material-symbols-rounded"> landscape </span>Example Use Case 3: UI Example Retrieval</span></h3>
        
        <section class="example3 teaser mt-2">
            <img src="static/example-app-example-search.png" alt="A short slide animation showing the overivew of WebUI."></img>
        </section>
        
        <p>
            We built a web application that contains a search box where the user enters their query. Figure above shows the examples of the screens retrieved for a set of queries indexed by UIClip and the vanilla CLIP model.
            Our tool uses a similar procedure to our UI relevance evaluation, where model-computed embeddings are used to retrieve and sort screenshots based on the user’s query. 
            UIClip's score can take into account both the relevance and quality of retrieved examples, and we incorporate a negative prompt that biases the query vector away from simple or ambiguous designs
        </p>

        <!-- <br aria-hidden="true"/> -->

        <!-- <iframe
        src="https://biglab-webui-screensim.hf.space"
        frameborder="0"
        width="1000"
        height="1000"
    ></iframe> -->

    </section>



    <section id="citation">
        <h3 data-exclude-link><span><span class="me-1 material-symbols-rounded">quick_reference_all</span>Reference</span>
            <!-- <div>
                <a href="static/blobgan_paper.pdf" target="_blank" class="btn px-2 py-1 iconbutton btn-dark"><span class="me-1 material-symbols-rounded">file_download</span> Paper PDF</a>
            </div> -->
        </h3>
        <div class="cit_cont">
        <pre class="cit">@inproceedings{wu2024uiclip,
        title={UIClip: A Data-driven Model for Assessing User Interface Design},
        author={Wu, Jason and Peng, Yi-Hao and Li, Amanda Xin Yue and Swearngin, Amanda and Bigham, Jeffrey and Nichols, Jeffrey},
        booktitle={Proceedings of the ACM Symposium on User Interface Software and Technology (UIST)},
        year={2024}
}</pre>
        </div>
        </div>
    </section>
    <section>
        <h3 data-exclude-link>
            <div><span data-text="volunteer_activism" class=" me-2 material-symbols-rounded">partner_exchange
</span><span data-text="Acknowledgements">Acknowledgements</span>
            </div>
        </h3>
        <p>
            This work was funded in part by an NSF Graduate Research Fellowship.
        </p>
        <p>
            This webpage template was inspired and modified from <a href="https://dave.ml/blobgan/">the BlobGAN project</a>.
        </p>
    </section>
</main>



</body>
</html>
